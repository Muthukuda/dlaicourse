{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muthukuda/dlaicourse/blob/master/MIRNetv2_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Enriched Features for Fast Image Restoration and Enhancement (TPAMI 2022) [![paper](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/) \n",
        "\n",
        "<hr />\n",
        "\n",
        "This is a demo to run MIRNet_v2 on you own images for the following tasks\n",
        "- Real Image Denoising\n",
        "- Super-Resolution\n",
        "- Contrast Enhancement\n",
        "- Low-Light Image Enhancement"
      ],
      "metadata": {
        "id": "2TXV3h8zC9GN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRd46QaXlklQ"
      },
      "source": [
        "# 1. Setup\n",
        "- First, in the **Runtime** menu -> **Change runtime type**, make sure to have ```Hardware Accelerator = GPU```\n",
        "- Clone repo and install dependencies. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLDZ9t1pm9JZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.path.isdir('MIRNetv2'):\n",
        "  !rm -r MIRNetv2\n",
        "\n",
        "# Clone MIRNetv2\n",
        "!git clone https://github.com/swz30/MIRNetv2.git\n",
        "%cd MIRNetv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXxtBPA1tGxL"
      },
      "source": [
        "# 2. Define Task and Download Pre-trained Models\n",
        "Uncomment the task you would like to perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM4ksCkZtqUA"
      },
      "outputs": [],
      "source": [
        "# task = 'real_denoising'\n",
        "# task = 'super_resolution'\n",
        "# task = 'contrast_enhancement'\n",
        "task = 'lowlight_enhancement'\n",
        "\n",
        "# Download the pre-trained models\n",
        "if task is 'real_denoising':\n",
        "  !wget https://github.com/swz30/MIRNetv2/releases/download/v1.0.0/real_denoising.pth -P Real_Denoising/pretrained_models\n",
        "if task is 'super_resolution':\n",
        "  !wget https://github.com/swz30/MIRNetv2/releases/download/v1.0.0/sr_x4.pth -P Super_Resolution/pretrained_models\n",
        "if task is 'contrast_enhancement':\n",
        "  !wget https://github.com/swz30/MIRNetv2/releases/download/v1.0.0/enhancement_fivek.pth -P Enhancement/pretrained_models\n",
        "if task is 'lowlight_enhancement':\n",
        "  !wget https://github.com/swz30/MIRNetv2/releases/download/v1.0.0/enhancement_lol.pth -P Enhancement/pretrained_models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9nwA_Prt7PI"
      },
      "source": [
        "# 3. Upload Images\n",
        "Either download the sample images or upload your own images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC_q1NshvQHz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Download sample images\n",
        "!rm -r demo/*\n",
        "!wget https://github.com/swz30/MIRNetv2/releases/download/v1.0.0/sample_images.zip -P demo\n",
        "shutil.unpack_archive('demo/sample_images.zip', 'demo/')\n",
        "os.remove('demo/sample_images.zip')\n",
        "\n",
        "# OR Uncomment the following block if you would like to upload your own images. \n",
        "\"\"\"\n",
        "!rm -r demo/*\n",
        "input_dir = 'demo/sample_images/'+task+'/degraded'\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  input_path = os.path.join(input_dir, filename)\n",
        "  shutil.move(filename, input_path)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ArqQfvBbRf"
      },
      "source": [
        "# 4. Prepare Model and Load Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOJN6gHGCKGK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from runpy import run_path\n",
        "from skimage import img_as_ubyte\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "def get_weights_and_parameters(task, parameters):\n",
        "    if task == 'real_denoising':\n",
        "        weights = os.path.join('Real_Denoising', 'pretrained_models', 'real_denoising.pth')\n",
        "    elif task == 'super_resolution':\n",
        "        weights = os.path.join('Super_Resolution', 'pretrained_models', 'sr_x4.pth')\n",
        "        parameters['scale'] =  4\n",
        "    elif task == 'contrast_enhancement':\n",
        "        weights = os.path.join('Enhancement', 'pretrained_models', 'enhancement_fivek.pth')\n",
        "    elif task == 'lowlight_enhancement':\n",
        "        weights = os.path.join('Enhancement', 'pretrained_models', 'enhancement_lol.pth')\n",
        "    return weights, parameters\n",
        "\n",
        "\n",
        "# Get model weights and parameters\n",
        "parameters = {\n",
        "    'inp_channels':3,\n",
        "    'out_channels':3, \n",
        "    'n_feat':80,\n",
        "    'chan_factor':1.5,\n",
        "    'n_RRG':4,\n",
        "    'n_MRB':2,\n",
        "    'height':3,\n",
        "    'width':2,\n",
        "    'bias':False,\n",
        "    'scale':1,\n",
        "    'task': task\n",
        "    }\n",
        "\n",
        "weights, parameters = get_weights_and_parameters(task, parameters)\n",
        "\n",
        "load_arch = run_path(os.path.join('basicsr', 'models', 'archs', 'mirnet_v2_arch.py'))\n",
        "model = load_arch['MIRNet_v2'](**parameters)\n",
        "model.cuda()\n",
        "\n",
        "checkpoint = torch.load(weights)\n",
        "model.load_state_dict(checkpoint['params'])\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDvxkztWDsYd"
      },
      "source": [
        "# 5. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odPtmz_lD2Rd"
      },
      "outputs": [],
      "source": [
        "input_dir = 'demo/sample_images/'+task+'/degraded'\n",
        "out_dir = 'demo/sample_images/'+task+'/restored'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "extensions = ['jpg', 'JPG', 'png', 'PNG', 'jpeg', 'JPEG', 'bmp', 'BMP']\n",
        "files = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "\n",
        "img_multiple_of = 4\n",
        "\n",
        "print(f\"\\n ==> Running {task} with weights {weights}\\n \")\n",
        "with torch.no_grad():\n",
        "  for filepath in tqdm(files):\n",
        "      # print(file_)\n",
        "      torch.cuda.ipc_collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
        "      input_ = torch.from_numpy(img).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "\n",
        "      # Pad the input if not_multiple_of 4\n",
        "      h,w = input_.shape[2], input_.shape[3]\n",
        "      H,W = ((h+img_multiple_of)//img_multiple_of)*img_multiple_of, ((w+img_multiple_of)//img_multiple_of)*img_multiple_of\n",
        "      padh = H-h if h%img_multiple_of!=0 else 0\n",
        "      padw = W-w if w%img_multiple_of!=0 else 0\n",
        "      input_ = F.pad(input_, (0,padw,0,padh), 'reflect')\n",
        "\n",
        "      restored = model(input_)\n",
        "      restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "      # Unpad the output\n",
        "      restored = restored[:,:,:h,:w]\n",
        "\n",
        "      restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "      restored = img_as_ubyte(restored[0])\n",
        "\n",
        "      filename = os.path.split(filepath)[-1]\n",
        "      cv2.imwrite(os.path.join(out_dir, filename),cv2.cvtColor(restored, cv2.COLOR_RGB2BGR))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bwDss7ui1y2"
      },
      "source": [
        "# 6. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm5gyBgzlONb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "inp_filenames = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "out_filenames = natsorted(glob(os.path.join(out_dir, '*')))\n",
        "\n",
        "## Will display only first 5 images\n",
        "num_display_images = 5\n",
        "if len(inp_filenames)>num_display_images:\n",
        "  inp_filenames = inp_filenames[:num_display_images]\n",
        "  out_filenames = out_filenames[:num_display_images]\n",
        "\n",
        "print(f\"Results: {task}\")\n",
        "for inp_file, out_file in zip(inp_filenames, out_filenames):\n",
        "  degraded = cv2.cvtColor(cv2.imread(inp_file), cv2.COLOR_BGR2RGB)\n",
        "  restored = cv2.cvtColor(cv2.imread(out_file), cv2.COLOR_BGR2RGB)\n",
        "  ## Display Images\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "  dpi = fig.get_dpi()\n",
        "  fig.set_size_inches(900/ dpi, 448 / dpi)\n",
        "  plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
        "  axes[0].axis('off')\n",
        "  axes[0].imshow(degraded)\n",
        "  axes[1].axis('off')\n",
        "  axes[1].imshow(restored)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9TuiD7OtX9V"
      },
      "source": [
        "# 7. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yVqiRjflYll"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "zip_filename = f\"Restormer_{task}.zip\"\n",
        "os.system(f\"zip -r {zip_filename} demo/sample_images/{task}\")\n",
        "files.download(zip_filename)"
      ]
    }
  ]
}